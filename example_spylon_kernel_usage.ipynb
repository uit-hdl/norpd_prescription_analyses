{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spylon kernel usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spylon-kernel shares the same spark runtime between Spark(scala) and PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cells are by default running scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We may hop into the python runtime by using the %%python magic keyword in the beginning of a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import sys\n",
    "print(sys.version)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may import source code from any folder in the repository (I prefer to store the code in the source folder)\n",
    "* Scala code goes into src/scala\n",
    "* Python code goes into stc/python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the plotfig magic function from helpers\n",
    "Spylon-kernel needs some workarounds to enable the drawing of figures using the python runtime. Specifically, visualizations need to be output to a temporary file, and an image object containing the temporary file must be passed as a return argument to the kernel. This is all packed into the plotfig_magic() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import tempfile\n",
    "from IPython.display import Image\n",
    "def plotfig_magic():\n",
    "    fo = tempfile.NamedTemporaryFile(suffix=\".png\", mode=\"w\")\n",
    "    fo.close()\n",
    "    plt.savefig(fo.name)\n",
    "    return Image(filename=fo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "##### Replace the use of plt.show() with retval=plotfig_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "#Import helper files from src folder\n",
    "from src.python.helpers import plotfig_magic\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import tempfile\n",
    "\n",
    "plt.clf()\n",
    "ax = plt.plot([1,2,3], [3,2,5])\n",
    "retval = plotfig_magic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the use of scala and python\n",
    "\n",
    "Example: Create dataset with scala (usually we would load it from some source and transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "val values = List((1,1),(2,2),(4,3),(8,4),(16,5),(32,6))\n",
    "val df = spark.createDataFrame(values).toDF(\"x\", \"y\")\n",
    "df.printSchema\n",
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the dataframe as a table in the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"exampletable\")\n",
    "spark.sql(\"show tables\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now open it using python's spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "spark.sql(\"show tables\").show()\n",
    "exampletable = spark.sql(\"select * from exampletable\")\n",
    "exampletable.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot the data contained within the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "df = exampletable.toPandas()\n",
    "print(df)\n",
    "plt.clf()\n",
    "df.plot(x=\"x\",y=\"y\")\n",
    "retval=plotfig_magic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
