{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"src/scala/register_tables.scala\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_tables(spark, \"spark-warehouse/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val npr_raw = spark.read.option(\"header\",true).csv(\"datasets/npr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_raw.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val npr_red = npr_raw\n",
    "    .drop(\"innmate\", \"pasfylke\", \"institusjon_navn\", \"omsorgsnivå\" )\n",
    "    // recast diffdager_ut and diffdager_inn to integer\n",
    "    .withColumn(\"diffdager_inn2\", $\"diffdager_inn\".cast(\"Int\"))\n",
    "        .drop(\"diffdager_inn\").withColumnRenamed(\"diffdager_inn2\",\"diffdager_inn\")\n",
    "    .withColumn(\"diffdager_ut2\", $\"diffdager_ut\".cast(\"Int\"))\n",
    "        .drop(\"diffdager_ut\").withColumnRenamed(\"diffdager_ut2\",\"diffdager_ut\")\n",
    "npr_red.select(\"pasientlopenr\")\n",
    "    .count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_red.show(5)\n",
    "npr_red.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_red.select(\"aldersgrp\").groupBy(\"aldersgrp\").count.sort(asc(\"aldersgrp\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Take only løpenr from npr dataset\n",
    "val npr_lopenr = npr_red.select(\"pasientlopenr\")\n",
    "    .where(\"pasientlopenr is not null\")\n",
    "    .groupBy(\"pasientlopenr\")\n",
    "    .count\n",
    "    .select($\"pasientlopenr\", $\"count\".as(\"num_hospitalizations\"))\n",
    "    .distinct\n",
    "//take all elders with hospitalizations\n",
    "val elder_hosp_ids = spark.sql(\"select * from elders\")\n",
    "    .where(\"diff_utleveringdato is not null\")\n",
    "    .groupBy(\"id\")\n",
    "    .count\n",
    "    .select($\"id\",$\"count\".as(\"n_prescriptions\"))\n",
    "    .distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(npr_lopenr.count)\n",
    "println(elder_hosp_ids.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We perform an inner join on the IDs(Løpenr) from the elders and NPR datasets, in order to include only hospitalizations of patients who are present in the elders set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val npr_from_elders = npr_lopenr.join(elder_hosp_ids)\n",
    "    .where(\"pasientlopenr == id\")\n",
    "    .distinct\n",
    "    .sort(desc(\"num_hospitalizations\"))\n",
    "    .drop(\"pasientlopenr\")\n",
    "    .select(\"id\",\"num_hospitalizations\",\"n_prescriptions\")\n",
    "npr_from_elders.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save table of hospitalizations with patients that exist in the elders dataset\n",
    "* include num_hospitalizations and n_prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val npr_hospitalizations_from_elders = npr_from_elders.join(npr_red)\n",
    ".where(\"pasientlopenr == id\")\n",
    "\n",
    "npr_hospitalizations_from_elders.write.mode(SaveMode.Overwrite).parquet(\"spark-warehouse/npr_elders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select patients with less than 5 hospitalizations\n",
    "### Note that these are all patients also in the elders dataset\n",
    "* 72238 patients in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_lopenr.where(col(\"num_hospitalizations\")<=5).count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
